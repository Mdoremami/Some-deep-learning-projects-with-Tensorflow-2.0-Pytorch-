# -*- coding: utf-8 -*-
"""Pytorch Final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o86LUb9MwxBEAHhEO8yCRkqxW9Pvsjdr
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


# GPU
use_cuda = torch.cuda.is_available()
device = torch.device('cuda:0' if use_cuda else 'cpu')
print(use_cuda)

# Seeding
torch.manual_seed(16)
np.random.seed(16)

# Variables Defining
samples = 10**5
training_samples = int(0.8*samples)
data_dim = 200
sparsity = 7
encoder_dim = 6*sparsity
decoder_dim0 = encoder_dim + 10
decoder_dim1 = decoder_dim0 + 20
decoder_dim2 = decoder_dim1 + 15

# Creating dataset
tmp0 = torch.zeros(samples,data_dim)
random_sel = torch.zeros(samples,data_dim)
signal = tmp0
for i in range(samples):
  random_sel[i,:] = torch.randperm(data_dim)
  signal[i,random_sel[i,0:sparsity].numpy()] = 1
signal = signal.to(device)
sparsity_check = signal[:].sum()
if sparsity_check==samples*sparsity: 
  print('Sparsity_Check : ',True)
else:
  print('Sparsity_Check : ',False)

# # Adding Noise to data... (OPTIONAL)
# noise = torch.zeros_like(signal)
# for i in range(samples):
#   noise[i,:] = torch.randn(1,data_dim)

# signal = signal + 0.2 * noise

# Training & Testing sets
training_set = signal[0:training_samples,:]
testing_set = signal[training_samples:,:]

# # A quick example to give you insight about what happened above
# a=np.arange(10)
# print(a)
# print(a[0:8])
# print(a[8:11])
# print(a[8:])

# Batching Dataset
batching_factor = 5
trainloader = torch.utils.data.DataLoader(training_set , batch_size = batching_factor , shuffle = True)
testloader = torch.utils.data.DataLoader(testing_set , batch_size = batching_factor , shuffle = True)

# # See some data
# dataiter = iter(trainloader)
# tmp1 = dataiter.next()
# print(tmp1.shape,'\n',tmp1)

# Neural Network Defining
class Autoencoder(nn.Module):
  def __init__(self):
    super().__init__()
    self.encoder = nn.Linear(data_dim,encoder_dim)    # Encoding
    self.decoder0 = nn.Linear(encoder_dim,decoder_dim0)  # Decoding... Every 3 layres, decoding dimension increases
    self.bn0 = nn.BatchNorm1d(decoder_dim0)
    self.dr0 = nn.Dropout(0.5)
    self.decoder1 = nn.Linear(decoder_dim0,decoder_dim0)
    self.bn1 = nn.BatchNorm1d(decoder_dim0)
    self.dr01 = nn.Dropout(0.5)
    self.decoder2 = nn.Linear(decoder_dim0,decoder_dim1)
    self.bn2 = nn.BatchNorm1d(decoder_dim1)
    self.dr1 = nn.Dropout(0.5)
    self.decoder3 = nn.Linear(decoder_dim1,decoder_dim1)
    self.bn3 = nn.BatchNorm1d(decoder_dim1)
    self.dr12 = nn.Dropout(0.5)
    self.decoder4 = nn.Linear(decoder_dim1,decoder_dim1)
    self.bn4 = nn.BatchNorm1d(decoder_dim1)
    self.dr13 = nn.Dropout(0.5)
    self.decoder5 = nn.Linear(decoder_dim1,decoder_dim2)
    self.bn5 = nn.BatchNorm1d(decoder_dim2)
    self.dr2 = nn.Dropout(0.5)
    self.decoder6 = nn.Linear(decoder_dim2,decoder_dim2)
    self.bn6 = nn.BatchNorm1d(decoder_dim2)
    self.dr21 = nn.Dropout(0.5)
    self.decoder7 = nn.Linear(decoder_dim2,decoder_dim2)
    self.bn7 = nn.BatchNorm1d(decoder_dim2)
    self.dr22 = nn.Dropout(0.5)
    self.decoder8 = nn.Linear(decoder_dim2,data_dim)
  
  def forward(self,x):
    
    x = self.encoder(x)
    x = F.relu(self.decoder0(x))
    x = self.bn0(x)
    x = self.dr0(x)
    x = F.relu(self.decoder1(x))
    x = self.bn1(x)
    x = self.dr01(x)
    x = F.relu(self.decoder2(x))
    x = self.bn2(x)
    x = self.dr1(x)
    x = F.relu(self.decoder3(x))
    x = self.bn3(x)
    x = self.dr12(x)
    x = F.relu(self.decoder4(x))
    x = self.bn4(x)
    x = self.dr13(x)
    x = F.relu(self.decoder5(x))
    x = self.bn5(x)
    x = self.dr2(x)
    x = F.relu(self.decoder6(x))
    x = self.bn6(x)
    x = self.dr21(x)
    x = F.relu(self.decoder7(x))
    x = self.bn7(x)
    x = self.dr22(x)
    x = F.relu(self.decoder8(x))

    return(x)

# Defining Net
autoencoder = Autoencoder()
autoencoder.cuda()
params = autoencoder.parameters()

# Defining the Optimizer and Loss Functions
optimizer = optim.Adam(params, lr=0.003)
# criterion = nn.MSELoss()
criterion = nn.SmoothL1Loss()

# Training the net
for epoch in range(1):
  running_loss = 0
  for ind,dat in enumerate(trainloader,0):    # 80000 training samples / 5 (batch size) == 16000 totaly
    batch_outputs = autoencoder(dat)
    batch_outputs = batch_outputs.view(-1,1)
    dat = dat.view(-1,1)
    optimizer.zero_grad()
    loss = criterion(batch_outputs,dat)
    loss.backward()
    optimizer.step()
    running_loss += loss.item()
    print(loss.item())
    # if ind % 2000 == 1999:                   # Shows every 2000 trainings
    #   print('Epoch #%d , %d Data Trained , Average Loss : %f'%(epoch+1 , ind+1 , running_loss/2000))
    #   running_loss = 0

print('Ladies & Gentlemen; Training is finished!')

# Predicting the testing_set
predicted_values = torch.zeros(int(len(signal[training_samples:,:])/batching_factor),batching_factor,data_dim)
predicted_indices = torch.zeros(int(len(signal[training_samples:,:])/batching_factor),batching_factor,data_dim)
real_values = torch.zeros(int(len(signal[training_samples:,:])/batching_factor),batching_factor,data_dim)
real_indices = torch.zeros(int(len(signal[training_samples:,:])/batching_factor),batching_factor,data_dim)
with torch.no_grad():
  for i,dat in enumerate(testloader,0):
    real_val,real_ind = torch.sort(dat, descending=True)
    real_values[i,:,:] = real_val
    real_indices[i,:,:] = real_ind
    batch_outputs = autoencoder(dat)
    predicted_val, predicted_index = torch.sort(batch_outputs, descending=True)
    predicted_values[i,:,:] = predicted_val
    predicted_indices[i,:,:] = predicted_index
predicted_values = predicted_values.view(-1,data_dim)
predicted_indices = predicted_indices.view(-1,data_dim) 
real_values = real_values.view(-1,data_dim)
real_indices = real_indices.view(-1,data_dim)

# Indicx Accuracy
counter_ind=0
for i in range(len(testing_set)):
  for j in predicted_indices[i,0:sparsity]:
    if j in real_indices[i,0:sparsity]:
      counter_ind = counter_ind+1
total_ind = len(testing_set) * sparsity
print('Accuracy of Indices is : %d %%'%(100*counter_ind/total_ind))

# Value Accuracy
counter_val=0
Difference = (real_values - predicted_values)
for i in range(len(testing_set)):
  for j in range(data_dim):
    if Difference[i,j]<10**-2:
      counter_val = counter_val+1
total_val = len(testing_set) * data_dim      
print('Accuracy of values for 0.01 error threshold is : %d %%'%(100*counter_val/total_val))

# Visualizing
print(real_values[0,:])
print(real_indices[0,:])
print(predicted_values[0,:])
print(predicted_indices[0,:])

outputs2 = autoencoder(testing_set)

plt.plot(predicted_values[5,:],'o')
plt.plot(real_values[5,:],'x')
plt.show

print(batch_outputs.shape)

plt.plot(testing_set[830,:].cpu().numpy(),'o')
plt.plot(outputs2[830,:].cpu().detach().numpy(),'x')

print(outputs2.shape)

import time

t = time.time()

time.time()-t

# Saving the model     
# https://colab.research.google.com/github/agungsantoso/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%206%20-%20Saving%20and%20Loading%20Models.ipynb
torch.save(autoencoder.state_dict,'Aut_S7_Lr0002.pth')
files.download('Aut_S7_Lr0002.pth')

import os
import torch
import torchvision
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import save_image
import numpy as np
import torch.nn as nn
import torch.nn.functional as F

import pandas as pd
import random
# from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset
import matplotlib.pyplot as plt

N = 10
M = 5
S = 2 

class moein(nn.Module):
    def __init__(self):
        super(moein, self).__init__()
        #encoder
        self.x1 = nn.Linear(N,M)
        #Decoder
        # self.x2 = nn.Linear(M,N)
        self.x2 = nn.Linear(M,18)
        self.x3 = nn.Linear(18,30)
        self.x4 = nn.Linear(30,20)
        self.x5 = nn.Linear(20,N)
        
    def forward(self,x):
        x = self.x1(x)
        x = F.relu(x)
        x = self.x2(x)
        x = F.relu(x)
        x = self.x3(x)
        x = F.relu(x)
        x = self.x4(x)
        x = F.relu(x)
        x = self.x5(x)
        return x

class SparseDataset(torch.utils.data.Dataset):
    def __init__(self, S_Dim=10, S_Ord=2, NData=1000, transform=None):
        self.S_Dim = S_Dim
        self.S_Ord = S_Ord
        self.NData = NData
        self.transform = transform
        self.alldata = torch.zeros(NData,S_Dim)
        for i in range(NData):
            self.alldata[i,random.sample(range(S_Dim), S_Ord)]=1+torch.rand(S_Ord)
    def __len__(self):
        return self.NData
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        sample = self.alldata[idx,:]

        if self.transform:
            sample = self.transform(sample)

        return sample
d = SparseDataset(N,S,100000)
dataloader = DataLoader(d, batch_size=40)
x=moein()
ef = nn.MSELoss()
optimizer = torch.optim.Adam(x.parameters(), lr=1e-3, weight_decay=1e-5)
for iep in range(50):
    for i_batch, sample_batched in enumerate(dataloader):
        output = x(sample_batched)
        loss = ef(output, sample_batched)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    print(iep,loss.data)